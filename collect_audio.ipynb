{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import keyboard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "\n",
    "#import pynput.keyboard\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib tk\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "p = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVAILABLE DEVICES:\n",
      "\n",
      "0: Microsoft Sound Mapper - Input : MME\n",
      "1: Microphone (High Definition Aud : MME\n",
      "2: Microsoft Sound Mapper - Output : MME\n",
      "3: Speakers (High Definition Audio : MME\n",
      "4: Speakers (High Definition Audio Device) : Windows WASAPI\n",
      "5: Microphone (High Definition Audio Device) : Windows WASAPI\n",
      "6: Output () : Windows WDM-KS\n",
      "7: Microphone (HD Audio Mixed capture) : Windows WDM-KS\n",
      "8: Speakers (HD Audio Speaker) : Windows WDM-KS\n",
      "9: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(Synergy)) : Windows WDM-KS\n",
      "10: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(Synergy)) : Windows WDM-KS\n",
      "11: Input (Game Capture HD60 Pro Audio) : Windows WDM-KS\n",
      "12: Headphones () : Windows WDM-KS\n",
      "13: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(TOZO-T9)) : Windows WDM-KS\n",
      "14: Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(TOZO-T9)) : Windows WDM-KS\n",
      "15: Headphones () : Windows WDM-KS\n",
      "\n",
      "SELECTED: Speakers (High Definition Audio Device)\n"
     ]
    }
   ],
   "source": [
    "print ('AVAILABLE DEVICES:\\n')\n",
    "for i in range(0, p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    print( str(info['index']) + ': %s : %s' % (info['name'],\n",
    "                                                   p.get_host_api_info_by_index(info['hostApi'])['name']))\n",
    "    pass\n",
    "\n",
    "# Choose Speakers (2- Logitech G430 Gaming Headset) Windows WASAPI\n",
    "device_id = 4\n",
    "device_info = p.get_device_info_by_index(device_id)\n",
    "if device_info['maxInputChannels'] > device_info['maxOutputChannels']:\n",
    "    channels = device_info['maxInputChannels']\n",
    "else: channels = device_info['maxOutputChannels']\n",
    "\n",
    "print('\\nSELECTED:', device_info['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 4,\n",
       " 'structVersion': 2,\n",
       " 'name': 'Speakers (High Definition Audio Device)',\n",
       " 'hostApi': 1,\n",
       " 'maxInputChannels': 0,\n",
       " 'maxOutputChannels': 2,\n",
       " 'defaultLowInputLatency': 0.0,\n",
       " 'defaultLowOutputLatency': 0.0026666999999999997,\n",
       " 'defaultHighInputLatency': 0.0,\n",
       " 'defaultHighOutputLatency': 0.01,\n",
       " 'defaultSampleRate': 48000.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_device_info_by_index(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 2048 # Two data streams\n",
    "rate = int(device_info['defaultSampleRate'])\n",
    "\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=channels,\n",
    "                rate=rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=chunk,\n",
    "                input_device_index=device_id,\n",
    "                as_loopback=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk size (C) is equal to hop length. This means there is 1 window per chunk, and a FFT is performed on each chunk of audio data. That is, a FFT is performed on 1024/48000 (s) = 21.3 ms worth of audio information. Then, n_frames (n) is the number of frames you can fit in a set duration per chunk size C. The audio buffer takes the dimensions n x C. Operations take place to convert the column information (chunked audio data) to frequencies on the mel scale and are fit to a dimension specified by n_mels (m). The dimensions of the mel spectrogram take the form m x n, where m are the bins for the mel frequencies, and n is the number of frames that is set for a duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 1 # seconds\n",
    "hop_length = 1024\n",
    "n_frames = int(np.ceil(rate * duration / hop_length))\n",
    "n_fft = 1024\n",
    "#window_size = n_fft\n",
    "n_mels=128\n",
    "y_axis = 'mel'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working spectrograms (BOTH AUDIO CHANNELS)\n",
    "\n",
    "audio_buffer = [np.zeros((n_frames, chunk)), np.zeros((n_frames, chunk))]\n",
    "print(audio_buffer[0].shape)\n",
    "\n",
    "S, S_db = [], []\n",
    "for i in range(2):\n",
    "    S.append(np.zeros((n_mels, n_frames)))\n",
    "    S_db.append(np.zeros((n_mels, n_frames)))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True, figsize=(10,5))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read audio stream data and normalize \n",
    "\n",
    "    data = stream.read(chunk) \n",
    "    data = np.frombuffer(data, np.int16).reshape(chunk, 2) # (1024, 2)\n",
    "    #data = data.astype(np.float32) / np.iinfo(np.int16).max # normalize audio data\n",
    "\n",
    "    for idx, side_audio_data in enumerate([data[:,0], data[:,1]]):\n",
    "\n",
    "        audio_buffer[idx] = np.roll(audio_buffer[idx], shift=-1, axis=0)\n",
    "        audio_buffer[idx][-1, :] = side_audio_data\n",
    "\n",
    "        S[idx] = librosa.feature.melspectrogram(audio_buffer[idx].flatten(),\n",
    "                                            sr=rate,\n",
    "                                            n_fft=n_fft,\n",
    "                                            n_mels=n_mels, \n",
    "                                            hop_length=hop_length,\n",
    "                                            fmax=rate/2) \n",
    "\n",
    "        S_db[idx] = librosa.power_to_db(S[idx], ref=1)\n",
    "\n",
    "        ax[idx].clear()\n",
    "\n",
    "        img = librosa.display.specshow(S_db[idx],\n",
    "                                        ax=ax[idx],\n",
    "                                        sr=rate,\n",
    "                                        n_fft=n_fft,\n",
    "                                        x_axis='time',\n",
    "                                        y_axis=y_axis, \n",
    "                                        fmax=rate/2, \n",
    "                                        hop_length=hop_length)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('c'):\n",
    "        if fig: plt.close(fig)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working spectrogram (LEFT AUDIO CHANNEL ONLY)\n",
    "\n",
    "audio_buffer = np.zeros((n_frames, chunk))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read audio stream data and normalize \n",
    "\n",
    "    data = stream.read(chunk) \n",
    "    data = np.frombuffer(data, np.int16).reshape(chunk, 2) # (1024, 2)\n",
    "    #data = data.astype(np.float32) / np.iinfo(np.int16).max # normalize audio data\n",
    "    audio_data = data[:,0] # JUST PLOTTING LEFT AUDIO CHANNEL RIGHT NOW\n",
    "    #print(audio_data.shape)\n",
    "\n",
    "    audio_buffer = np.roll(audio_buffer, -1, axis=0)\n",
    "    audio_buffer[-1, :] = audio_data\n",
    "    #print(len(audio_buffer.flatten()))\n",
    "\n",
    "    S = librosa.feature.melspectrogram(audio_buffer.flatten(),\n",
    "                                       sr=rate,\n",
    "                                       n_fft=n_fft,\n",
    "                                       n_mels=n_mels, \n",
    "                                       hop_length=hop_length,\n",
    "                                       fmax=rate/2) \n",
    "\n",
    "    #print(S.shape)\n",
    "    S_db = librosa.power_to_db(S,ref=1) # (n_mels=128, 187)\n",
    "    #print(S_db.shape)\n",
    "    # print(np.max(S_db), np.min(S_db)) # (128, 187)\n",
    "\n",
    "    ax.clear()\n",
    "    img = librosa.display.specshow(S_db,\n",
    "                                   ax=ax,\n",
    "                                   sr=rate,\n",
    "                                   n_fft=n_fft,\n",
    "                                   x_axis='time',\n",
    "                                   y_axis=y_axis, \n",
    "                                   fmax=rate/2, \n",
    "                                   hop_length=hop_length)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('c'):\n",
    "        if fig: plt.close(fig)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do: add type in name for footsteps, gunshots, maybe even breathing **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['left+-', 'left+up+-', 'left+down+-', 'up+-', 'down+-', 'right+up+-', 'right+down+-', 'right+-', 'control+-', 'left+*', 'left+up+*', 'left+down+*', 'up+*', 'down+*', 'right+up+*', 'right+down+*', 'right+*', 'control+*', 'left+/', 'left+up+/', 'left+down+/', 'up+/', 'down+/', 'right+up+/', 'right+down+/', 'right+/', 'control+/', 'left+.', 'left+up+.', 'left+down+.', 'up+.', 'down+.', 'right+up+.', 'right+down+.', 'right+.', 'control+.', 'left+Ins', 'left+up+Ins', 'left+down+Ins', 'up+Ins', 'down+Ins', 'right+up+Ins', 'right+down+Ins', 'right+Ins', 'control+Ins', 'left+1', 'left+up+1', 'left+down+1', 'up+1', 'down+1', 'right+up+1', 'right+down+1', 'right+1', 'control+1']\n"
     ]
    }
   ],
   "source": [
    "# Creating hotkeys for saving files\n",
    "\n",
    "directions = {\n",
    "    ('left',): 'hardLeft',\n",
    "    ('left', 'up'): 'softLeftFront',\n",
    "    ('left', 'down'): 'softLeftBack',\n",
    "    ('up',): 'front',\n",
    "    ('down',): 'back',\n",
    "    ('right', 'up'): 'softRightFront',\n",
    "    ('right', 'down'): 'softRightBack',\n",
    "    ('right',): 'hardRight',\n",
    "    ('control',): 'center'\n",
    "}\n",
    "\n",
    "sound_class = {'-': '_footstep',\n",
    "               '*': '_gunshot',\n",
    "               '/': '_voice',\n",
    "               '.': '_breathing', # refers to wounded breathing, need to rename\n",
    "               'Ins': '_healing',\n",
    "               '1': '_exhausted'} # refers to exhausted breathing\n",
    "\n",
    "source = 'EFT'\n",
    "\n",
    "\n",
    "\n",
    "def save_audio(hotkey, audio_buffer, S_db, count):\n",
    "    \n",
    "    direction = directions[tuple(hotkey.split('+')[:-1])]\n",
    "    sound = sound_class[hotkey.split('+')[-1]]\n",
    "    title = direction+'_'+source+sound+'_'+str(count[direction+'_'+source+sound])\n",
    "    count[direction+'_'+source+sound] += 1\n",
    "\n",
    "    parameters = {\n",
    "        'audio_buffer': audio_buffer,\n",
    "        'S_db': S_db\n",
    "    }\n",
    "\n",
    "    print('Saving', title)\n",
    "    \n",
    "    with open('AudioData/'+title, 'wb') as file:\n",
    "        pickle.dump(parameters, file)\n",
    "\n",
    "\n",
    "hotkeys = []\n",
    "\n",
    "for sound in sound_class.keys():\n",
    "    for keys in directions.keys():\n",
    "        for idx, key in enumerate(keys):\n",
    "            if idx == 0: key_strings = key\n",
    "            else: key_strings += '+'+key\n",
    "        #print(key_strings)\n",
    "        final_hotkey = key_strings + '+'+sound\n",
    "        hotkeys.append(final_hotkey)\n",
    "\n",
    "print(hotkeys)\n",
    "\n",
    "\n",
    "\n",
    "def init_count(hotkeys):\n",
    "\n",
    "     count = {}\n",
    "\n",
    "     for hotkey in hotkeys:\n",
    "\n",
    "          direction = directions[tuple(hotkey.split('+')[:-1])]\n",
    "          sound = sound_class[hotkey.split('+')[-1]]\n",
    "          count[direction+'_'+source+sound] = 0\n",
    "          \n",
    "     return count\n",
    "\n",
    "def create_hotkeys(hotkeys):\n",
    "    for hotkey in hotkeys:\n",
    "        keyboard.add_hotkey(hotkey, save_audio, args=[hotkey, audio_buffer, S_db, count], timeout=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to run above code block several times to work? May have to do with initialized variables ! OR may need to wait ~1 minute !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving hardLeft_EFT_breathing_0\n",
      "Saving hardLeft_EFT_breathing_1\n",
      "Saving hardLeft_EFT_breathing_2\n",
      "Saving front_EFT_breathing_0\n",
      "Saving front_EFT_breathing_1\n",
      "Saving front_EFT_breathing_2\n",
      "Saving front_EFT_breathing_3\n",
      "Saving front_EFT_breathing_4\n",
      "Saving front_EFT_breathing_5\n",
      "Saving hardRight_EFT_breathing_0\n",
      "Saving hardRight_EFT_breathing_1\n",
      "Saving hardRight_EFT_breathing_2\n",
      "Saving front_EFT_breathing_6\n",
      "Saving front_EFT_breathing_7\n",
      "Saving front_EFT_breathing_8\n",
      "Saving center_EFT_footstep_0\n",
      "Saving center_EFT_footstep_1\n",
      "Saving center_EFT_footstep_2\n",
      "Saving center_EFT_footstep_3\n",
      "Saving center_EFT_footstep_4\n",
      "Saving center_EFT_footstep_5\n",
      "Saving hardLeft_EFT_footstep_0\n",
      "Saving hardLeft_EFT_footstep_1\n",
      "Saving hardLeft_EFT_footstep_2\n",
      "Saving front_EFT_footstep_0\n",
      "Saving front_EFT_footstep_1\n",
      "Saving front_EFT_footstep_2\n",
      "Saving front_EFT_footstep_3\n",
      "Saving hardLeft_EFT_breathing_3\n",
      "Saving hardLeft_EFT_breathing_4\n",
      "Saving hardLeft_EFT_breathing_5\n",
      "Saving hardLeft_EFT_breathing_6\n",
      "Saving hardLeft_EFT_breathing_7\n",
      "Saving center_EFT_healing_0\n",
      "Saving hardLeft_EFT_breathing_8\n",
      "Saving front_EFT_breathing_9\n",
      "Saving front_EFT_breathing_10\n",
      "Saving front_EFT_breathing_11\n",
      "Saving back_EFT_breathing_0\n",
      "Saving back_EFT_breathing_1\n",
      "Saving back_EFT_breathing_2\n",
      "Saving back_EFT_breathing_3\n",
      "Saving back_EFT_breathing_4\n",
      "Saving back_EFT_breathing_5\n",
      "Saving back_EFT_breathing_6\n",
      "Saving back_EFT_breathing_7\n",
      "Saving back_EFT_breathing_8\n",
      "Saving back_EFT_breathing_9\n",
      "Saving hardRight_EFT_breathing_3\n",
      "Saving hardRight_EFT_breathing_4\n",
      "Saving hardRight_EFT_breathing_5\n",
      "Saving front_EFT_breathing_12\n",
      "Saving front_EFT_breathing_13\n",
      "Saving front_EFT_breathing_14\n",
      "Saving front_EFT_breathing_15\n",
      "Saving front_EFT_breathing_16\n",
      "Saving front_EFT_breathing_17\n",
      "Saving front_EFT_breathing_18\n",
      "Saving hardLeft_EFT_breathing_9\n",
      "Saving hardLeft_EFT_breathing_10\n",
      "Saving hardLeft_EFT_breathing_11\n",
      "Saving hardLeft_EFT_breathing_12\n",
      "Saving hardLeft_EFT_breathing_13\n",
      "Saving hardLeft_EFT_breathing_14\n",
      "Saving hardLeft_EFT_breathing_15\n",
      "Saving hardLeft_EFT_breathing_16\n",
      "Saving hardLeft_EFT_breathing_17\n",
      "Saving center_EFT_footstep_6\n",
      "Saving center_EFT_footstep_7\n",
      "Saving center_EFT_footstep_8\n",
      "Saving center_EFT_footstep_9\n",
      "Saving center_EFT_footstep_10\n",
      "Saving center_EFT_footstep_11\n",
      "Saving center_EFT_footstep_12\n",
      "Saving center_EFT_footstep_13\n",
      "Saving center_EFT_footstep_14\n",
      "Saving center_EFT_footstep_15\n",
      "Saving center_EFT_footstep_16\n",
      "Saving center_EFT_footstep_17\n",
      "Saving center_EFT_footstep_18\n",
      "Saving center_EFT_footstep_19\n",
      "Saving center_EFT_footstep_20\n",
      "Saving center_EFT_footstep_21\n",
      "Saving center_EFT_footstep_22\n",
      "Saving center_EFT_footstep_23\n",
      "Saving center_EFT_footstep_24\n",
      "Saving center_EFT_footstep_25\n",
      "Saving center_EFT_footstep_26\n",
      "Saving center_EFT_footstep_27\n",
      "Saving center_EFT_footstep_28\n",
      "Saving center_EFT_footstep_29\n",
      "Saving center_EFT_footstep_30\n",
      "Saving center_EFT_footstep_31\n",
      "Saving back_EFT_voice_0\n",
      "Saving back_EFT_voice_1\n",
      "Saving back_EFT_voice_2\n",
      "Saving back_EFT_voice_3\n",
      "Saving back_EFT_voice_4\n",
      "Saving back_EFT_voice_5\n",
      "Saving back_EFT_voice_6\n",
      "Saving front_EFT_breathing_19\n",
      "Saving front_EFT_breathing_20\n",
      "Saving front_EFT_breathing_21\n",
      "Saving hardLeft_EFT_breathing_18\n",
      "Saving hardLeft_EFT_breathing_19\n",
      "Saving hardLeft_EFT_breathing_20\n",
      "Saving hardLeft_EFT_breathing_21\n",
      "Saving front_EFT_breathing_22\n",
      "Saving front_EFT_breathing_23\n",
      "Saving front_EFT_breathing_24\n",
      "Saving front_EFT_breathing_25\n",
      "Saving front_EFT_breathing_26\n",
      "Saving front_EFT_breathing_27\n",
      "Saving front_EFT_breathing_28\n",
      "Saving front_EFT_breathing_29\n",
      "Saving back_EFT_breathing_10\n",
      "Saving back_EFT_breathing_11\n",
      "Saving back_EFT_breathing_12\n",
      "Saving back_EFT_breathing_13\n",
      "Saving front_EFT_breathing_30\n",
      "Saving front_EFT_breathing_31\n",
      "Saving front_EFT_breathing_32\n",
      "Saving hardRight_EFT_breathing_6\n",
      "Saving hardRight_EFT_breathing_7\n",
      "Saving hardRight_EFT_breathing_8\n",
      "Saving hardRight_EFT_breathing_9\n",
      "Saving hardRight_EFT_breathing_10\n",
      "Saving hardRight_EFT_breathing_11\n",
      "Saving hardRight_EFT_breathing_12\n",
      "Saving hardRight_EFT_breathing_13\n",
      "Saving hardRight_EFT_breathing_14\n",
      "Saving hardRight_EFT_breathing_15\n",
      "Saving hardRight_EFT_breathing_16\n",
      "Saving hardRight_EFT_breathing_17\n",
      "Saving hardRight_EFT_breathing_18\n",
      "Saving hardRight_EFT_breathing_19\n",
      "Saving hardRight_EFT_breathing_20\n",
      "Saving hardRight_EFT_breathing_21\n",
      "Saving hardRight_EFT_breathing_22\n",
      "Saving hardRight_EFT_breathing_23\n",
      "Saving hardRight_EFT_breathing_24\n",
      "Saving hardRight_EFT_breathing_25\n",
      "Saving hardRight_EFT_breathing_26\n",
      "Saving hardRight_EFT_breathing_27\n",
      "Saving hardRight_EFT_breathing_28\n",
      "Saving hardRight_EFT_breathing_29\n",
      "Saving hardRight_EFT_breathing_30\n",
      "Saving hardRight_EFT_breathing_31\n",
      "Saving hardRight_EFT_breathing_32\n",
      "Saving hardRight_EFT_breathing_33\n",
      "Saving hardRight_EFT_footstep_0\n",
      "Saving hardRight_EFT_footstep_1\n",
      "Saving hardRight_EFT_footstep_2\n",
      "Saving hardRight_EFT_footstep_3\n",
      "Saving hardRight_EFT_footstep_4\n",
      "Saving hardRight_EFT_footstep_5\n",
      "Saving hardRight_EFT_footstep_6\n",
      "Saving hardRight_EFT_voice_0\n",
      "Saving hardRight_EFT_voice_1\n",
      "Saving hardRight_EFT_voice_2\n",
      "Saving hardRight_EFT_voice_3\n",
      "Saving center_EFT_footstep_32\n",
      "Saving center_EFT_footstep_33\n",
      "Saving center_EFT_footstep_34\n",
      "Saving center_EFT_footstep_35\n",
      "Saving center_EFT_gunshot_0\n",
      "Saving front_EFT_gunshot_0\n",
      "Saving front_EFT_gunshot_1\n"
     ]
    }
   ],
   "source": [
    "# Audio array collection (BOTH AUDIO CHANNELS)\n",
    "\n",
    "duration = 1 # seconds\n",
    "hop_length = 1024\n",
    "n_frames = int(np.ceil(rate * duration / hop_length))\n",
    "n_fft = 1024\n",
    "#window_size = n_fft\n",
    "n_mels=128\n",
    "y_axis = 'mel'\n",
    "\n",
    "# Initialize data collectors\n",
    "\n",
    "audio_buffer = [np.zeros((n_frames, chunk)), np.zeros((n_frames, chunk))]\n",
    "\n",
    "S, S_db = [], []\n",
    "for i in range(2):\n",
    "    S.append(np.zeros((n_mels, n_frames)))\n",
    "    S_db.append(np.zeros((n_mels, n_frames)))\n",
    "\n",
    "# Set up count and hotkeys\n",
    "\n",
    "count = init_count(hotkeys)\n",
    "create_hotkeys(hotkeys)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read audio stream data and normalize \n",
    "\n",
    "    data = stream.read(chunk) \n",
    "    data = np.frombuffer(data, np.int16).reshape(chunk, 2) # (1024, 2)\n",
    "\n",
    "    for idx, side_audio_data in enumerate([data[:,0], data[:,1]]):\n",
    "\n",
    "        audio_buffer[idx] = np.roll(audio_buffer[idx], shift=-1, axis=0)\n",
    "        audio_buffer[idx][-1, :] = side_audio_data\n",
    "\n",
    "        S[idx] = librosa.feature.melspectrogram(audio_buffer[idx].flatten(),\n",
    "                                            sr=rate,\n",
    "                                            n_fft=n_fft,\n",
    "                                            n_mels=n_mels, \n",
    "                                            hop_length=hop_length,\n",
    "                                            fmax=rate/2) \n",
    "\n",
    "        S_db[idx] = librosa.power_to_db(S[idx], ref=1)\n",
    "\n",
    "\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('c'):\n",
    "        break\n",
    "\n",
    "\n",
    "keyboard.unhook_all_hotkeys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ff175135632c6ed055a673727c4fdf32c227ab3ac13e4382fbf4e9ac594a27f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
